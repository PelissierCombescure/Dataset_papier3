{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`blender_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4999999999999996\n",
      "4.330127018922194\n",
      "2.4999999999999996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import trimesh\n",
    "from scipy.spatial.transform import Rotation\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from utils import *\n",
    "from fonction_PtofView import *\n",
    "\n",
    "path_rendu_dir = '/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModenelNet40'\n",
    "R = 5\n",
    "# voir equations cahier\n",
    "# 12 caméras à 30° d'écart\n",
    "step = int(360/12)\n",
    "d = R*math.sin(math.radians(step)); print(d)\n",
    "r = R*math.cos(math.radians(step)); print(r)\n",
    "# élévation par rapport au centre de l'objet == plan équateur\n",
    "elevation = 30\n",
    "Z = R*math.sin(math.radians(elevation)); print(Z) # lié à l'élévation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Circular_12_elevation_30\n",
    "Fichier blender : Rendu/ModenelNet40/circular_config_12_elevation_30.blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replicate_structure('/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/my_circular_12_elevation_30', '/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/my_circular_12_elevation_30_remeshing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circular_config_12_elevation_30 = pd.DataFrame(columns=['object', 'LocationX', 'LocationY', 'LocationZ', 'RotationX', 'RotationY', 'RotationZ'])\n",
    "circular_config_12_elevation_30.loc[0] = ['objet', 0, 0, 0, 0, 0, 0]\n",
    "circular_config_12_elevation_30.loc[1] = ['cam1', 0, -1*R, Z, 90-elevation, 0, 0]\n",
    "circular_config_12_elevation_30.loc[2] = ['cam2', d, -1*r, Z, 90-elevation, 0, 30]\n",
    "circular_config_12_elevation_30.loc[3] = ['cam3', r, -1*d, Z, 90-elevation, 0, 60]\n",
    "circular_config_12_elevation_30.loc[4] = ['cam4', R, 0, Z, 90-elevation, 0, 90]\n",
    "circular_config_12_elevation_30.loc[5] = ['cam5', r, d, Z, 90-elevation, 0, 120]\n",
    "circular_config_12_elevation_30.loc[6] = ['cam6', d, r, Z, 90-elevation, 0, 150]\n",
    "circular_config_12_elevation_30.loc[7] = ['cam7', 0, R, Z, 90-elevation, 0, 180]\n",
    "circular_config_12_elevation_30.loc[8] = ['cam8', -1*d, r, Z, 90-elevation, 0, 210]\n",
    "circular_config_12_elevation_30.loc[9] = ['cam9', -1*r, d, Z, 90-elevation, 0, 240]\n",
    "circular_config_12_elevation_30.loc[10] = ['cam10', -1*R, 0, Z, 90-elevation, 0, 270]\n",
    "circular_config_12_elevation_30.loc[11] = ['cam11', -1*r, -1*d, Z, 90-elevation, 0, 300]\n",
    "circular_config_12_elevation_30.loc[12] = ['cam12', -1*d, -1*r, Z, 90-elevation, 0, 330]\n",
    "\n",
    "## sauvegarde du fichier csv avec les paramètres des cameras pour blender\n",
    "#circular_config_12_elevation_30.to_csv(os.path.join(path_rendu_dir,\"circular_config_12_elevation_30.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circular_config_12_elevation_30 = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/circular_config_12_elevation_30.csv\")\n",
    "circular_config_12_elevation_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour 1 fichier OBJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_mesh = '/home/pelissier/These-ATER/Papier_international3/Dataset/ModelNet40_centered_scaled/piano/train/piano_0001_SMPLER_centered_scaled.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichiers manquant pour run1\n",
    "paths_mesh = read_paths_from_txt('/home/pelissier/These-ATER/Papier_international3/Dataset/paths_files/obj_files_ModelNet40_centered_scaled_remeshing1-1000.txt')\n",
    "path_mesh = paths_mesh[0]; print(path_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output = '/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/my_circular_12_elevation_30_remeshing'\n",
    "\n",
    "## Récupération du nom du fichier\n",
    "directory, filename = os.path.split(path_mesh)\n",
    "name = filename.split('.')[0] # ex:  piano_0001_centered_scaled\n",
    "directory_output = directory.replace('/home/pelissier/These-ATER/Papier_international3/Dataset/ModelNet40_centered_scaled', dir_output)\n",
    "print(directory_output); print(name)\n",
    "## Récupération des coordonnées des sommets, des faces et des normales\n",
    "mesh = trimesh.load_mesh(path_mesh)\n",
    "array_coords = np.array(mesh.vertices); nb_vertices = len(array_coords) \n",
    "array_faces = np.array(mesh.faces); nb_faces = len(array_faces)\n",
    "## Utiliser le dictionnaire adjacent_faces obtenu précédemment\n",
    "adjacent_faces = find_adjacent_faces(array_faces)\n",
    "idx_faces_per_idx_vert = find_faces_for_vertices(adjacent_faces)\n",
    "array_normals = np.array(mesh.vertex_normals)\n",
    "array_normals_face = np.array(mesh.face_normals)\n",
    "centroid = np.around(get_centroid(array_faces, array_coords),2); print('centroid',centroid)\n",
    "diagonal = compute_bounding_box_diagonal(np.array(mesh.bounding_box.vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cam k\n",
    "for k in tqdm.tqdm(range(1,circular_config_12_elevation_30.shape[0])):\n",
    "    data_blender_cam = circular_config_12_elevation_30.loc[k].to_dict()\n",
    "    # Data de la projection\n",
    "    focale = 300*diagonal; W_image = 400; H_image = 400\n",
    "    # Positon 3D de la caméra \n",
    "    cam = np.array([data_blender_cam['LocationX'], data_blender_cam['LocationY'], data_blender_cam['LocationZ']])\n",
    "    # POI : centre du mesh\n",
    "    lookat = centroid\n",
    "    # vecteur de direction \n",
    "    d = lookat - cam\n",
    "    # vecteur up\n",
    "    # ATTENTION il y a -1 car un a l'axe y vers le haut (?)\n",
    "    up = np.array([0, 0, -1])\n",
    "    # Projection : Monde --> Caméra\n",
    "    #Matrice de passage entre le repère Monde --> repère Caméra # j'ai verifié : \n",
    "    # np.around(np.dot(WorldToCamera,np.array(list(cam)+[1])),5) = [0,0,0,1]\n",
    "    WorldToCamera = get_worldTocamera_matrix(cam, lookat, up)\n",
    "    # coordonnées des sommets dans le repère caméra\n",
    "    array_coords_camera = monde_to_camera(WorldToCamera, array_coords) #[vertices, 1]\n",
    "    # Projection des normals dans le repère caméra ie on n'applique que la rotation et nn la translation \n",
    "    R = WorldToCamera[:3,:3]\n",
    "    array_normals_camera = np.transpose(np.dot(R, np.transpose(array_normals)))\n",
    "    array_normals_camera_norm = np.array(normalisation(array_normals_camera[:,:3]))\n",
    "    ## Pareil : projection + normalisation des normales des faces \n",
    "    array_normals_face_camera = np.transpose(np.dot(R, np.transpose(array_normals_face)))\n",
    "    array_normals_face_camera_norm = np.array(normalisation(array_normals_face_camera[:,:3]))\n",
    "    ### Projection: Caméra -> image 2D\n",
    "    ## On recupère les indices des sommets visibles\n",
    "    array_pixels = camera_to_image(focale, W_image, H_image, array_coords_camera)\n",
    "    dephtMap, _, _ = get_visible_vertices(W_image, H_image, array_faces, array_pixels, array_coords_camera, array_normals_camera_norm)\n",
    "    \n",
    "    ####################################################################################################\n",
    "    ### FACES VISIBLES - Back face culling\n",
    "    ## Centre de chaque face : coord des centre de chaque face \n",
    "    arr_centre_faces = np.array([compute_face_centre(f, array_coords_camera[:,:3]) for f in array_faces])\n",
    "    ## On veut l'angle entre la normale de la face et le vecteur [cam, face_centre] dans le repère caméra\n",
    "    ## comme on est dans le repère caméra, les coord 3D de la caméra sont (0,0,0) vu que par principe le repère caméra est centré en la caméra.\n",
    "    ## Donc : cam - face_centre = - face_centre\n",
    "    rayons = -1*arr_centre_faces.copy()\n",
    "    ## normalisation des rayons sortants\n",
    "    ## vecteur avec la 1/norme de chaque ligne == chaque centre\n",
    "    vect_norm = 1/np.linalg.norm(rayons, axis=1)\n",
    "    ## on reshape en nb_facesx1\n",
    "    vect_norm = np.reshape(vect_norm, (rayons.shape[0],1))\n",
    "    ## on repete le vecteur sur 3colonnes car on a des coords 3D / face\n",
    "    matrix_norm = np.matlib.repmat(vect_norm, 1, 3)\n",
    "    ## produit terme a terme \n",
    "    rayons_norm = rayons*matrix_norm\n",
    "    ## normal de face dans le repère camera qui est déjà normalisé\n",
    "    normales_face_norm = array_normals_face_camera_norm.copy()\n",
    "    ## produit scalaire entre rayon et normale faces\n",
    "    ## produit scalaire = |a|*|b|*cos(a,b) or a et b sont normalisé, donc ici on a : cos(a,b)\n",
    "    arr_cos = np.sum(rayons_norm*normales_face_norm, axis=1)\n",
    "    ## face visible si cos >= 0\n",
    "    epsilon_cos = 10e-5\n",
    "    idx_faces_visibles = np.where(arr_cos >= epsilon_cos)[0]\n",
    "\n",
    "    ############################################################\n",
    "    ### FACES VISIBLES - filtrage occultations\n",
    "    vrai_idx_faces_visibles = filtrage_faces_occultees2(arr_centre_faces, idx_faces_visibles, dephtMap, focale, W_image, H_image, epsilon_z=10e-2)\n",
    "    \n",
    "    ############################################################\n",
    "    ### SOMMETS VISIBLES\n",
    "    idx_vert_visible = find_vertices_with_visible_faces(idx_faces_per_idx_vert, np.array(vrai_idx_faces_visibles))\n",
    "\n",
    "    ############################################################\n",
    "    ### SOMMETS VISIBLES - filtrage on garde vraiment ceux qui ont un cos >0\n",
    "    rayons = -1*array_coords_camera[list(idx_vert_visible)][:,:3].copy()\n",
    "    ## normalisation des rayons sortants\n",
    "    # vecteur avec la 1/norme de chaque ligne == chaque vertex\n",
    "    vect_norm = 1/np.linalg.norm(rayons, axis=1)\n",
    "    # on reshape en nb_sommetx1\n",
    "    vect_norm = np.reshape(vect_norm, (rayons.shape[0],1))\n",
    "    # on repete le vecteur sur 3colonnes car on a des coords 3D /vertice\n",
    "    matrix_norm = np.matlib.repmat(vect_norm, 1, 3)\n",
    "    # produit terme a terme \n",
    "    rayons_norm = rayons*matrix_norm\n",
    "    ## normal de pt_index dans le repère camera qui est déjà normalisé\n",
    "    normales_norm = array_normals_camera_norm[list(idx_vert_visible)].copy()\n",
    "    # produit scalaire entre vertice et sa normale\n",
    "    # produit scalaire = |a|*|b|*cos(a,b) or a et b sont normalisé, donc ici on a : cos(a,b)\n",
    "    arr_cos_vert = np.sum(rayons_norm*normales_norm, axis=1)\n",
    "    vrai_idx_vert_visible = np.array(list(idx_vert_visible))[np.where(arr_cos_vert>0)]\n",
    "\n",
    "    ######################################################################################################\n",
    "    ## Surface Totale 3D\n",
    "    surface3D = 0\n",
    "    for idx_f in range(array_faces.shape[0]):\n",
    "        face = array_faces[idx_f, :]\n",
    "        ## coord 3D des 3 sommets la face visible courante dans le rep camera\n",
    "        sommet0 = array_coords[face[0],:]\n",
    "        sommet1 = array_coords[face[1],:]\n",
    "        sommet2 = array_coords[face[2],:]\n",
    "        ## surface 3D\n",
    "        surface3D = surface3D + calculer_aire_triangle_3D(sommet0, sommet1, sommet2)\n",
    "    \n",
    "    ## Surface visible de la projection courante \n",
    "    arr_coords_cam = array_coords_camera[:,:3]\n",
    "    surface3D_visible = 0\n",
    "    for idx_f in range(len(vrai_idx_faces_visibles)):\n",
    "        face = array_faces[idx_f, :]\n",
    "        ## coord 3D des 3 sommets la face visible courante dans le rep camera\n",
    "        sommet0 = arr_coords_cam[face[0],:]\n",
    "        sommet1 = arr_coords_cam[face[1],:]\n",
    "        sommet2 = arr_coords_cam[face[2],:]\n",
    "        ## surface 3D\n",
    "        surface3D_visible = surface3D_visible + calculer_aire_triangle_3D(sommet0, sommet1, sommet2)    \n",
    "    \n",
    "    ######################################################################################################\n",
    "            \n",
    "    ## Affichage des depthmaps\n",
    "    if False :   \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(dephtMap, cmap='viridis', interpolation='nearest')\n",
    "        plt.colorbar(label=\"Depth (units)\")\n",
    "        plt.title(\"Camera \"+str(k))\n",
    "        plt.xlabel(\"Width (pixels)\")\n",
    "        plt.ylabel(\"Height (pixels)\")\n",
    "        plt.show()\n",
    "    \n",
    "    ## Sauvegarde des données\n",
    "    obj_filename = os.path.join(directory_output,name+\"_cam\"+str(k)+\"_v2.obj\")\n",
    "    write_obj_with_color(array_coords_camera, array_faces, vrai_idx_vert_visible, obj_filename)\n",
    "\n",
    "\n",
    "    ## Sauvegarde des données\n",
    "    arrays_output_path = os.path.join(directory_output,name+\"_cam\"+str(k)+\"_metadata_arrays.npz\")\n",
    "    values_output_path = os.path.join(directory_output,name+\"_cam\"+str(k)+\"_metadata_values.pkl\")\n",
    "\n",
    "    # Step 1: Save all array data in a compressed .npz file\n",
    "    np.savez_compressed(\n",
    "        arrays_output_path,\n",
    "        centroid=centroid,\n",
    "        array_coords_camera=array_coords_camera,\n",
    "        array_normals_camera=array_normals_camera,\n",
    "        array_normals_camera_norm=array_normals_camera_norm,\n",
    "        array_pixels=array_pixels,\n",
    "        dephtMap=dephtMap,\n",
    "        vrai_idx_vert_visible=vrai_idx_vert_visible,\n",
    "        vrai_idx_faces_visibles=vrai_idx_faces_visibles,\n",
    "        surface3D=surface3D,\n",
    "        surface3D_visible=surface3D_visible)\n",
    "\n",
    "    # Step 2: Save scalar values and metadata in a separate file using pickle\n",
    "    metadata = {\n",
    "        \"camera_k\": k, \n",
    "        \"nb_vertices\": nb_vertices, \"nb_faces\": nb_faces,\n",
    "        \"diagonal\": diagonal,\n",
    "        \"data_blender_cam\": data_blender_cam,\n",
    "        \"focale\": focale,\n",
    "        \"W_image\": W_image, \"H_image\": H_image,\n",
    "        \"cam\": cam, \"lookat\": lookat, \"up\": up,\n",
    "        \"WorldToCamera\": WorldToCamera}\n",
    "    with open(values_output_path, \"wb\") as f: pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PBL durant execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier run sur les 1000 premiers mesh --> fichier error : error_run_blender.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root of outputs folder\n",
    "dir_output = '/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/my_circular_12_elevation_30'\n",
    "\n",
    "# Paths of mesh\n",
    "mesh_paths = read_paths_from_txt('/home/pelissier/These-ATER/Papier_international3/Dataset/paths_files/obj_SMPLER_files_ModelNet40_centered_scaled.txt')[:1000]\n",
    "\n",
    "pbl = []\n",
    "\n",
    "for path_mesh in mesh_paths:\n",
    "    ## Récupération du nom du fichier\n",
    "    directory, filename = os.path.split(path_mesh)\n",
    "    name = filename.split('.')[0] # ex:  piano_0001_centered_scaled\n",
    "    directory_output = directory.replace('/home/pelissier/These-ATER/Papier_international3/Dataset/ModelNet40_centered_scaled', dir_output)\n",
    "    \n",
    "    for k in range(1,13):\n",
    "        # fichier NPZ\n",
    "        npz_file_cam_k =  os.path.join(directory_output,name+\"_cam\"+str(k)+\"_metadata_arrays.npz\")\n",
    "        # fichier PKL\n",
    "        pkl_file_cam_k = os.path.join(directory_output,name+\"_cam\"+str(k)+\"_metadata_values.pkl\")\n",
    "        # fichier OBJ\n",
    "        obj_file_cam_k = os.path.join(directory_output,name+\"_cam\"+str(k)+\"_v2.obj\")\n",
    "        \n",
    "        if not(os.path.exists(npz_file_cam_k)): \n",
    "            #print(os.path.basename(npz_file_cam_k))\n",
    "            name_pbl_npz = os.path.basename(npz_file_cam_k)\n",
    "            pbl.append(name_pbl_npz.split('_cam')[0])\n",
    "            \n",
    "        if not(os.path.exists(pkl_file_cam_k)): \n",
    "            #print(os.path.basename(pkl_file_cam_k))\n",
    "            name_pbl_pkl = os.path.basename(pkl_file_cam_k)\n",
    "            pbl.append(name_pbl_pkl.split('_cam')[0])\n",
    "            \n",
    "        if not(os.path.exists(obj_file_cam_k)): \n",
    "            #print(os.path.basename(obj_file_cam_k))\n",
    "            name_pbl_obj = os.path.basename(obj_file_cam_k)\n",
    "            pbl.append(name_pbl_obj.split('_cam')[0])\n",
    "        \n",
    "# OBJ with problem : missing files    \n",
    "list(set(pbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir du dossier d'erreur\n",
    "run1 = read_paths_from_txt('/home/pelissier/These-ATER/Papier_international3/Dataset/error_run_blender.txt')\n",
    "pbl_from_run1 = [x.split('_cam')[0].split(' ')[-1] for x in run1 if 'pbl' in x]\n",
    "pbl_from_run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
